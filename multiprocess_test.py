
'''
i want to figure out how to funnel work generated by a population of workers into a batch processor that returns the results in a way that they can be used again

concrete example of my problem:
	1) i want, say, 6 parallel games with 6 workers per game
		these workers would be:
			running up and down their respective trees,
			identifying nodes that need expanding,
			converting the game state to a model input,
			submitting (model_input, queue_of_originating_mcts_instance, ref_to_originating_leaf) to the batch_processing_queue
	2) i want this batch_processing_queue to:
		check to see if the queue is a certain size (16? 32? 64?) or if a certain amount of time has passed (1ms? 10ms?),
		prepare an input matrix of an appropriate size, fill it with things off the queue, correlating the owning node with the input,
		do inference, correlate the results with the owning nodes,
		submit the (policy_target, value_target, owning_node) back to the queue of the originating mcts instance
	3) the workers on the mcts tree will prioritize items from their results queues and will only return to the simulation step when the result queue is empty
'''















